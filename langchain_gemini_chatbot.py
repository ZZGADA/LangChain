#!/usr/bin/env python3
"""
LangChain Gemini èŠå¤©æœºå™¨äºº - å®Œæ•´ç‰ˆ
ä½¿ç”¨ LangChain + LangGraph æ¡†æ¶æ„å»ºçš„èŠå¤©æœºå™¨äºº
å±•ç¤ºæ¡†æ¶çš„å®Œæ•´åŠŸèƒ½å’Œæœ€ä½³å®è·µ
"""

import os
import sys
import time
from typing import Annotated, List, Optional
from datetime import datetime

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser

from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver


class ChatState(TypedDict):
    """èŠå¤©çŠ¶æ€å®šä¹‰"""
    messages: Annotated[List, add_messages]
    user_info: Optional[dict]
    conversation_count: int
    last_activity: str


class LangChainGeminiBot:
    """åŸºäº LangChain çš„ Gemini èŠå¤©æœºå™¨äºº"""
    
    def __init__(self):
        self.llm = None
        self.graph = None
        self.memory = MemorySaver()  # å†…å­˜ä¿å­˜å™¨
        self.thread_config = {"configurable": {"thread_id": "main_conversation"}}
        
    def setup_api_key(self):
        """è®¾ç½®APIå¯†é’¥"""
        if not os.getenv("GOOGLE_API_KEY"):
            print("âŒ æœªæ£€æµ‹åˆ° GOOGLE_API_KEY ç¯å¢ƒå˜é‡")
            print("\nğŸ”‘ è·å–APIå¯†é’¥æ­¥éª¤ï¼š")
            print("1. è®¿é—®ï¼šhttps://aistudio.google.com/app/apikey")
            print("2. ç™»å½•Googleè´¦å·")
            print("3. åˆ›å»ºæ–°çš„APIå¯†é’¥")
            print("4. å¤åˆ¶å¯†é’¥")
            
            print("\nğŸ’¡ è¯·é€‰æ‹©è®¾ç½®æ–¹å¼ï¼š")
            print("1. ä¸´æ—¶è®¾ç½®ï¼ˆä»…æœ¬æ¬¡ä¼šè¯æœ‰æ•ˆï¼‰")
            print("2. æ°¸ä¹…è®¾ç½®ï¼ˆæ¨èï¼‰")
            
            choice = input("è¯·é€‰æ‹© (1/2): ").strip()
            
            if choice == "1":
                api_key = input("\nè¯·è¾“å…¥æ‚¨çš„ Google API Key: ").strip()
                if api_key:
                    os.environ["GOOGLE_API_KEY"] = api_key
                    print("âœ… API Key å·²ä¸´æ—¶è®¾ç½®")
                    return True
                else:
                    print("âŒ æœªè¾“å…¥APIå¯†é’¥")
                    return False
            elif choice == "2":
                print("\nğŸ”§ æ°¸ä¹…è®¾ç½®æ–¹æ³•ï¼š")
                print("åœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š")
                print("export GOOGLE_API_KEY='your-api-key-here'")
                print("\næˆ–è€…å°†ä¸Šè¿°å‘½ä»¤æ·»åŠ åˆ° ~/.bashrc æˆ– ~/.zshrc æ–‡ä»¶ä¸­")
                return False
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©")
                return False
        
        return True
    
    def test_network_connection(self):
        """æµ‹è¯•ç½‘ç»œè¿æ¥"""
        print("ğŸŒ æ­£åœ¨æµ‹è¯•ç½‘ç»œè¿æ¥...")
        try:
            import urllib.request
            import socket
            
            # æµ‹è¯•åŸºæœ¬ç½‘ç»œè¿æ¥
            socket.setdefaulttimeout(10)
            urllib.request.urlopen('https://www.google.com', timeout=10)
            print("âœ… ç½‘ç»œè¿æ¥æ­£å¸¸")
            
            # æµ‹è¯• Google AI API ç«¯ç‚¹
            try:
                urllib.request.urlopen('https://generativelanguage.googleapis.com', timeout=10)
                print("âœ… Google AI API ç«¯ç‚¹å¯è¾¾")
                return True
            except Exception as e:
                print(f"âš ï¸  Google AI API ç«¯ç‚¹è¿æ¥å¼‚å¸¸: {e}")
                print("ğŸ’¡ å¯èƒ½æ˜¯ç½‘ç»œé˜²ç«å¢™æˆ–ä»£ç†é—®é¢˜")
                return True  # å…è®¸ç»§ç»­å°è¯•
                
        except Exception as e:
            print(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥: {e}")
            print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ä»£ç†è®¾ç½®")
            return False
    
    def initialize_llm(self):
        """åˆå§‹åŒ–è¯­è¨€æ¨¡å‹"""
        try:
            print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– LangChain Gemini æ¨¡å‹...")
            
            # å…ˆæµ‹è¯•ç½‘ç»œè¿æ¥
            # if not self.test_network_connection():
            #     return False

            # å°è¯•ä¸åŒçš„æ¨¡å‹ï¼Œä¼˜å…ˆä½¿ç”¨ç¨³å®šç‰ˆæœ¬
            models_to_try = [
                ("gemini-2.5-pro", "æœ€æ–°ç‰ˆæœ¬"),
                ("gemini-1.5-flash", "ç¨³å®šç‰ˆæœ¬ï¼Œæ¨èä½¿ç”¨"),
                ("gemini-1.5-pro", "é«˜çº§ç‰ˆæœ¬"),
                ("gemini-pro", "ç»å…¸ç‰ˆæœ¬"),
                ("gemini-2.0-flash-exp", "å®éªŒç‰ˆæœ¬"),
            ]

            for model_name, description in models_to_try:
                try:
                    print(f"ğŸ§ª å°è¯•æ¨¡å‹: {model_name} ({description})")
                    
                    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼Œå¢åŠ è¶…æ—¶è®¾ç½®
                    self.llm = ChatGoogleGenerativeAI(
                        model=model_name,
                        temperature=0.7,
                        max_tokens=2000,
                        timeout=30,  # å¢åŠ è¶…æ—¶æ—¶é—´
                        max_retries=2,  # å‡å°‘é‡è¯•æ¬¡æ•°
                    )
                    
                    # æµ‹è¯•æ¨¡å‹è¿æ¥ï¼Œä½¿ç”¨ç®€å•çš„æ¶ˆæ¯
                    print("   ğŸ”„ æµ‹è¯•æ¨¡å‹è¿æ¥...")
                    test_response = self.llm.invoke(
                        [HumanMessage(content="Hi")], 
                        config={"timeout": 15}  # è®¾ç½®è°ƒç”¨è¶…æ—¶
                    )
                    
                    if test_response and test_response.content:
                        print(f"âœ… æˆåŠŸè¿æ¥åˆ° {model_name}")
                        print(f"   ğŸ“ æµ‹è¯•å“åº”: {test_response.content[:50]}...")
                        return True
                        
                except KeyboardInterrupt:
                    print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­äº†è¿æ¥æµ‹è¯•")
                    return False
                except Exception as e:
                    error_msg = str(e)
                    if "ServiceUnavailable" in error_msg or "UNAVAILABLE" in error_msg:
                        print(f"   âŒ {model_name} æœåŠ¡ä¸å¯ç”¨ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜")
                    elif "PERMISSION_DENIED" in error_msg:
                        print(f"   âŒ {model_name} æƒé™è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥")
                    elif "NOT_FOUND" in error_msg:
                        print(f"   âŒ {model_name} æ¨¡å‹ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨")
                    else:
                        print(f"   âŒ {model_name} è¿æ¥å¤±è´¥: {error_msg[:100]}...")
                    
                    # çŸ­æš‚ç­‰å¾…åå°è¯•ä¸‹ä¸€ä¸ªæ¨¡å‹
                    time.sleep(1)
                    continue
            
            print("âŒ æ‰€æœ‰æ¨¡å‹éƒ½è¿æ¥å¤±è´¥")
            print("\nğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š")
            print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            print("2. ç¡®è®¤APIå¯†é’¥æ˜¯å¦æ­£ç¡®ä¸”æœ‰æ•ˆ")
            print("3. æ£€æŸ¥æ˜¯å¦æœ‰é˜²ç«å¢™æˆ–ä»£ç†é˜»æ­¢è¿æ¥")
            print("4. ç¨åé‡è¯•ï¼Œå¯èƒ½æ˜¯æœåŠ¡æš‚æ—¶ä¸å¯ç”¨")
            print("5. å°è¯•ä½¿ç”¨å®æ—¶èŠå¤©ç‰ˆæœ¬ï¼špython gemini_realtime_chat.py")
            return False
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    def create_prompt_template(self):
        """åˆ›å»ºæç¤ºæ¨¡æ¿"""
        return ChatPromptTemplate.from_messages([
            SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€æ™ºèƒ½çš„AIåŠ©æ‰‹ï¼Œåå­—å« LangChain Gemini Botã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- ä½¿ç”¨ä¸­æ–‡è¿›è¡Œè‡ªç„¶æµç•…çš„å¯¹è¯
- èƒ½å¤Ÿè®°ä½å¯¹è¯å†å²å’Œä¸Šä¸‹æ–‡
- æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„ä¿¡æ¯å’Œå»ºè®®
- ä¿æŒä¸“ä¸šä½†å‹å¥½çš„è¯­è°ƒ
- å¯ä»¥è¿›è¡Œåˆ›æ„è®¨è®ºå’Œé—®é¢˜è§£å†³

å½“å‰æ—¶é—´ï¼š{current_time}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›æœ‰å¸®åŠ©çš„å›ç­”ã€‚"""),
            MessagesPlaceholder(variable_name="messages"),
        ])
    
    def chatbot_node(self, state: ChatState):
        """èŠå¤©æœºå™¨äººèŠ‚ç‚¹ - LangGraph çš„æ ¸å¿ƒå¤„ç†å•å…ƒ"""
        try:
            # è·å–å½“å‰æ—¶é—´
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            # åˆ›å»ºæç¤ºæ¨¡æ¿
            prompt = self.create_prompt_template()
            
            # åˆ›å»ºå¤„ç†é“¾
            chain = (
                {
                    "messages": lambda x: x["messages"],
                    "current_time": lambda x: current_time,
                }
                | prompt
                | self.llm
                | StrOutputParser()
            )
            
            # è°ƒç”¨å¤„ç†é“¾ï¼Œå¢åŠ è¶…æ—¶æ§åˆ¶
            response = chain.invoke(state, config={"timeout": 30})
            
            # æ›´æ–°çŠ¶æ€
            return {
                "messages": [AIMessage(content=response)],
                "conversation_count": state.get("conversation_count", 0) + 1,
                "last_activity": current_time,
            }
            
        except Exception as e:
            error_msg = f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {e}"
            print(f"âš ï¸  {error_msg}")
            return {
                "messages": [AIMessage(content="æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·é‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")],
                "conversation_count": state.get("conversation_count", 0),
                "last_activity": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            }
    
    def should_continue(self, state: ChatState):
        """å†³å®šæ˜¯å¦ç»§ç»­å¤„ç†"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å¤æ‚çš„é€»è¾‘åˆ¤æ–­
        # ä¾‹å¦‚ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ã€æ˜¯å¦éœ€è¦é¢å¤–å¤„ç†ç­‰
        return "continue"

    """
   1. åˆ›å»ºçŠ¶æ€å›¾ (StateGraph)ï¼šåˆå§‹åŒ–ä¸€ä¸ª StateGraph å¯¹è±¡ï¼Œå¹¶æŒ‡å®š ChatState ã€‚ChatState
      ç”¨æ¥åœ¨å·¥ä½œæµçš„æ¯ä¸€æ­¥ä¹‹é—´ä¼ é€’æ•°æ®ï¼ˆå¦‚æ¶ˆæ¯å†å²ã€ç”¨æˆ·ä¿¡æ¯ç­‰ï¼‰ã€‚
   2. æ·»åŠ èŠ‚ç‚¹ (Node)ï¼šå®ƒæ·»åŠ äº†ä¸€ä¸ªåä¸º "chatbot" çš„æ ¸å¿ƒèŠ‚ç‚¹ï¼Œè¿™ä¸ªèŠ‚ç‚¹å…³è”åˆ° self.chatbot_node æ–¹æ³•ã€‚èŠ‚ç‚¹æ˜¯å›¾ä¸­çš„åŸºæœ¬å¤„ç†å•å…ƒï¼Œchatbot_node
      è´Ÿè´£è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹å¹¶è·å–å›å¤ã€‚
   3. å®šä¹‰æµç¨‹è¾¹ (Edge)ï¼š
       * workflow.add_edge(START, "chatbot"): è¿™æ¡è¾¹å®šä¹‰äº†å·¥ä½œæµçš„å…¥å£ã€‚å½“å›¾å¼€å§‹æ‰§è¡Œæ—¶ï¼Œä¼šé¦–å…ˆè¿›å…¥ "chatbot" èŠ‚ç‚¹ã€‚
       * workflow.add_edge("chatbot", END): è¿™æ¡è¾¹å®šä¹‰äº† "chatbot" èŠ‚ç‚¹æ‰§è¡Œå®Œæ¯•åï¼Œå·¥ä½œæµå°±ç»“æŸäº†ã€‚
   4. ç¼–è¯‘å›¾ (Compile)ï¼šæœ€åï¼Œå®ƒè°ƒç”¨ workflow.compile(checkpointer=self.memory) æ¥å°†å®šä¹‰å¥½çš„èŠ‚ç‚¹å’Œè¾¹ç¼–è¯‘æˆä¸€ä¸ªå¯æ‰§è¡Œçš„å›¾ã€‚å…³é”®åœ¨äº
      checkpointer=self.memoryï¼Œå®ƒä¸ºå›¾æ·»åŠ äº†è®°å¿†åŠŸèƒ½ï¼Œä½¿å¾—æ¯æ¬¡è°ƒç”¨çš„çŠ¶æ€ï¼ˆæ¯”å¦‚å¯¹è¯å†å²ï¼‰éƒ½èƒ½è¢«ä¿å­˜å’Œæ¢å¤ã€‚

    
    """
    def build_graph(self):
        """æ„å»º LangGraph çŠ¶æ€å›¾"""
        try:
            print("ğŸ”¨ æ­£åœ¨æ„å»º LangGraph çŠ¶æ€å›¾...")
            
            # åˆ›å»ºçŠ¶æ€å›¾
            workflow = StateGraph(ChatState)
            
            # æ·»åŠ èŠ‚ç‚¹
            workflow.add_node("chatbot", self.chatbot_node)
            
            # æ·»åŠ è¾¹
            workflow.add_edge(START, "chatbot")
            workflow.add_edge("chatbot", END)
            
            # ç¼–è¯‘å›¾ï¼ˆå¸¦å†…å­˜ï¼‰
            self.graph = workflow.compile(checkpointer=self.memory)
            
            print("âœ… LangGraph çŠ¶æ€å›¾æ„å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ çŠ¶æ€å›¾æ„å»ºå¤±è´¥: {e}")
            return False
    
    def process_user_input(self, user_input: str):
        """å¤„ç†ç”¨æˆ·è¾“å…¥"""
        try:
            # åˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "conversation_count": 0,
                "last_activity": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            }
            
            # ä½¿ç”¨å›¾å¤„ç†ï¼Œå¢åŠ è¶…æ—¶æ§åˆ¶
            result = self.graph.invoke(
                initial_state, 
                config={
                    **self.thread_config,
                    "timeout": 45  # å¢åŠ å¤„ç†è¶…æ—¶æ—¶é—´
                }
            )
            
            # è·å–æœ€åä¸€æ¡AIæ¶ˆæ¯
            ai_messages = [msg for msg in result["messages"] if isinstance(msg, AIMessage)]
            if ai_messages:
                return ai_messages[-1].content
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å›å¤ã€‚"
                
        except Exception as e:
            error_msg = f"å¤„ç†è¾“å…¥æ—¶å‡ºé”™: {e}"
            print(f"âš ï¸  {error_msg}")
            return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†å¤„ç†é—®é¢˜ã€‚è¯·é‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚"
    
    def get_conversation_stats(self):
        """è·å–å¯¹è¯ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # ä»å†…å­˜ä¸­è·å–å½“å‰çŠ¶æ€
            current_state = self.graph.get_state(self.thread_config)
            if current_state and current_state.values:
                return {
                    "conversation_count": current_state.values.get("conversation_count", 0),
                    "last_activity": current_state.values.get("last_activity", "æœªçŸ¥"),
                    "message_count": len(current_state.values.get("messages", [])),
                }
        except:
            pass
        return {"conversation_count": 0, "last_activity": "æœªçŸ¥", "message_count": 0}
    
    def clear_memory(self):
        """æ¸…ç©ºå¯¹è¯è®°å¿†"""
        try:
            # é‡æ–°åˆ›å»ºå†…å­˜ä¿å­˜å™¨
            self.memory = MemorySaver()
            # é‡æ–°æ„å»ºå›¾
            workflow = StateGraph(ChatState)
            workflow.add_node("chatbot", self.chatbot_node)
            workflow.add_edge(START, "chatbot")
            workflow.add_edge("chatbot", END)
            self.graph = workflow.compile(checkpointer=self.memory)
            return True
        except Exception as e:
            print(f"æ¸…ç©ºè®°å¿†å¤±è´¥: {e}")
            return False
    
    def start_chat(self):
        """å¼€å§‹èŠå¤©"""
        print("ğŸ¤– LangChain Gemini èŠå¤©æœºå™¨äºº")
        print("=" * 60)
        print("âœ¨ åŸºäº LangChain + LangGraph æ¡†æ¶çš„æ™ºèƒ½å¯¹è¯")
        print("ğŸ§  æ”¯æŒå¯¹è¯è®°å¿†å’Œä¸Šä¸‹æ–‡ç†è§£")
        print("ğŸ’¡ è¾“å…¥ 'quit', 'exit', 'q' æˆ– 'é€€å‡º' ç»“æŸå¯¹è¯")
        print("-" * 60)
        
        # è®¾ç½®APIå¯†é’¥
        if not self.setup_api_key():
            print("âŒ APIå¯†é’¥è®¾ç½®å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return
        
        # åˆå§‹åŒ–æ¨¡å‹
        if not self.initialize_llm():
            print("âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            print("\nğŸ’¡ å¤‡ç”¨æ–¹æ¡ˆï¼š")
            print("1. å°è¯•å®æ—¶èŠå¤©ç‰ˆæœ¬ï¼špython gemini_realtime_chat.py")
            print("2. ä½¿ç”¨æœ¬åœ°ç¤ºä¾‹ï¼špython langchain_local_example.py")
            return
        
        # æ„å»ºå›¾
        if not self.build_graph():
            print("âŒ LangGraph æ„å»ºå¤±è´¥ï¼Œç¨‹åºé€€å‡º")
            return
        
        print("ğŸ‰ LangChain Gemini èŠå¤©æœºå™¨äººå·²å°±ç»ªï¼")
        print("ğŸ“‹ æ¡†æ¶ç‰¹æ€§ï¼š")
        print("   â€¢ LangChain ç»„ä»¶åŒ–æ¶æ„")
        print("   â€¢ LangGraph çŠ¶æ€ç®¡ç†")
        print("   â€¢ å¯¹è¯è®°å¿†åŠŸèƒ½")
        print("   â€¢ ç½‘ç»œå¼‚å¸¸å¤„ç†")
        print("   â€¢ å¯æ‰©å±•çš„å·¥ä½œæµ")
        print()
        
        # æ¬¢è¿æ¶ˆæ¯
        print("ğŸ¤– LangChain Gemini: ä½ å¥½ï¼æˆ‘æ˜¯åŸºäº LangChain æ¡†æ¶çš„ Gemini AI åŠ©æ‰‹ã€‚")
        print("æˆ‘å¯ä»¥è®°ä½æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼Œè¿›è¡Œæ›´æ™ºèƒ½çš„äº¤äº’ã€‚è¯·å‘Šè¯‰æˆ‘ä½ æƒ³èŠä»€ä¹ˆå§ï¼\n")
        
        # ä¸»å¯¹è¯å¾ªç¯
        while True:
            try:
                user_input = input("ğŸ‘¤ ä½ : ").strip()
                
                if not user_input:
                    print("ğŸ’­ è¯·è¾“å…¥ä¸€äº›å†…å®¹...")
                    continue
                
                if user_input.lower() in ["quit", "exit", "q", "é€€å‡º", "å†è§", "bye"]:
                    stats = self.get_conversation_stats()
                    print(f"ğŸ“Š å¯¹è¯ç»Ÿè®¡: {stats['conversation_count']} è½®å¯¹è¯, {stats['message_count']} æ¡æ¶ˆæ¯")
                    print("ğŸ‘‹ è°¢è°¢ä½¿ç”¨ LangChain Gemini èŠå¤©æœºå™¨äººï¼å†è§ï¼")
                    break
                
                # ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ["clear", "æ¸…ç©º", "é‡ç½®"]:
                    if self.clear_memory():
                        print("ğŸ”„ å¯¹è¯å†å²å·²æ¸…ç©º\n")
                    else:
                        print("âŒ æ¸…ç©ºå¤±è´¥\n")
                    continue
                
                if user_input.lower() in ["stats", "ç»Ÿè®¡", "çŠ¶æ€"]:
                    stats = self.get_conversation_stats()
                    print("ğŸ“Š å¯¹è¯ç»Ÿè®¡ä¿¡æ¯ï¼š")
                    print(f"   â€¢ å¯¹è¯è½®æ•°: {stats['conversation_count']}")
                    print(f"   â€¢ æ¶ˆæ¯æ€»æ•°: {stats['message_count']}")
                    print(f"   â€¢ æœ€åæ´»åŠ¨: {stats['last_activity']}\n")
                    continue
                
                if user_input.lower() in ["help", "å¸®åŠ©"]:
                    print("ğŸ“š å¯ç”¨å‘½ä»¤ï¼š")
                    print("   â€¢ clear/æ¸…ç©º - æ¸…ç©ºå¯¹è¯å†å²")
                    print("   â€¢ stats/ç»Ÿè®¡ - æ˜¾ç¤ºå¯¹è¯ç»Ÿè®¡")
                    print("   â€¢ help/å¸®åŠ© - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
                    print("   â€¢ quit/é€€å‡º - ç»“æŸå¯¹è¯\n")
                    continue
                
                # è·å–å¯¹è¯ç»Ÿè®¡
                stats = self.get_conversation_stats()
                print(f"ğŸ¤– LangChain Gemini (ç¬¬{stats['conversation_count']+1}è½®): ", end="", flush=True)
                
                # å¤„ç†ç”¨æˆ·è¾“å…¥
                response = self.process_user_input(user_input)
                
                # å®æ—¶æ‰“å°å“åº”ï¼ˆæ¨¡æ‹Ÿæ‰“å­—æ•ˆæœï¼‰
                import time
                for char in response:
                    print(char, end="", flush=True)
                    # time.sleep(0.01)
                
                print("\n")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ ç¨‹åºè¢«ä¸­æ–­ï¼Œå†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
                print("ğŸ’¡ è¯·é‡è¯•")


def main():
    """ä¸»å‡½æ•°"""
    try:
        bot = LangChainGeminiBot()
        bot.start_chat()
    except Exception as e:
        print(f"âŒ ç¨‹åºå¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥æ‚¨çš„ç¯å¢ƒé…ç½®")
        print("ğŸ”§ å¤‡ç”¨æ–¹æ¡ˆï¼š")
        print("1. python gemini_realtime_chat.py  # å®æ—¶èŠå¤©ç‰ˆæœ¬")
        print("2. python langchain_local_example.py  # æœ¬åœ°ç¤ºä¾‹ç‰ˆæœ¬")


if __name__ == "__main__":
    main() 